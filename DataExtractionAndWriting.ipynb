{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-30T22:37:40.732414Z","iopub.status.busy":"2023-10-30T22:37:40.731182Z","iopub.status.idle":"2023-10-30T22:38:03.342604Z","shell.execute_reply":"2023-10-30T22:38:03.341569Z","shell.execute_reply.started":"2023-10-30T22:37:40.732373Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import json\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","\n","from sqlalchemy import create_engine, text\n","!pip install PyMySql\n","import pymysql\n","import sqlalchemy\n","\n","!pip install ipython-sql\n","\n","#Import modules that related to SQL and connection to Azure\n","\n","#Create the engine so that we can get access to Azure MySQL\n","username = 'A12' # Your team name\n","password = 'A12password'\n","host = 'testproject.mysql.database.azure.com'\n","database = 'A12'  # Your team name\n","\n","connection_string = f\"mysql+pymysql://{username}:{password}@{host}/{database}\"\n","\n","ssl_args = {\n","    'ssl_ca': 'path_to/ca-cert.pem',\n","    'ssl_cert': 'path_to/client-cert.pem',\n","    'ssl_key': 'path_to/client-key.pem'\n","}\n","\n","engine = create_engine(\n","    connection_string,\n","    connect_args={'ssl': ssl_args}\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["I tried to install **mysqlclient** package as well, but the installation will fail for some reason. So I have to use **pymysql** for the following import data and query process."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T22:43:00.510438Z","iopub.status.busy":"2023-10-30T22:43:00.510043Z","iopub.status.idle":"2023-10-30T22:43:02.115039Z","shell.execute_reply":"2023-10-30T22:43:02.113654Z","shell.execute_reply.started":"2023-10-30T22:43:00.510407Z"},"trusted":true},"outputs":[],"source":["data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_checkin.json\")\n","data = []\n","for line in data_file:\n","  data.append(json.loads(line))\n","checkin_df = pd.DataFrame(data)\n","data_file.close()"]},{"cell_type":"markdown","metadata":{},"source":["The DF checkin's date column is too long for SQL, so going to split it to multiple rows"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T22:43:03.603159Z","iopub.status.busy":"2023-10-30T22:43:03.602649Z","iopub.status.idle":"2023-10-30T22:43:08.504005Z","shell.execute_reply":"2023-10-30T22:43:08.502761Z","shell.execute_reply.started":"2023-10-30T22:43:03.603121Z"},"trusted":true},"outputs":[],"source":["checkin_df['date'] = checkin_df['date'].str.split(',')\n","checkin_df_exploded = checkin_df.explode('date')\n","print(checkin_df_exploded)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T22:43:13.727482Z","iopub.status.busy":"2023-10-30T22:43:13.727074Z","iopub.status.idle":"2023-10-30T22:43:18.224668Z","shell.execute_reply":"2023-10-30T22:43:18.223407Z","shell.execute_reply.started":"2023-10-30T22:43:13.727450Z"},"trusted":true},"outputs":[],"source":["data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\")\n","data = []\n","for line in data_file:\n","  data.append(json.loads(line))\n","business_df = pd.DataFrame(data)\n","data_file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T22:43:20.958585Z","iopub.status.busy":"2023-10-30T22:43:20.958225Z","iopub.status.idle":"2023-10-30T22:45:23.029525Z","shell.execute_reply":"2023-10-30T22:45:23.028214Z","shell.execute_reply.started":"2023-10-30T22:43:20.958558Z"},"trusted":true},"outputs":[],"source":["data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\")\n","data = []\n","for line in data_file:\n","  data.append(json.loads(line))\n","review_df = pd.DataFrame(data)\n","data_file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T22:45:46.489360Z","iopub.status.busy":"2023-10-30T22:45:46.487883Z","iopub.status.idle":"2023-10-30T22:45:57.588558Z","shell.execute_reply":"2023-10-30T22:45:57.587505Z","shell.execute_reply.started":"2023-10-30T22:45:46.489293Z"},"trusted":true},"outputs":[],"source":["data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\")\n","data = []\n","for line in data_file:\n","  data.append(json.loads(line))\n","tip_df = pd.DataFrame(data)\n","data_file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T22:46:01.943273Z","iopub.status.busy":"2023-10-30T22:46:01.942865Z","iopub.status.idle":"2023-10-30T22:47:22.954327Z","shell.execute_reply":"2023-10-30T22:47:22.953050Z","shell.execute_reply.started":"2023-10-30T22:46:01.943242Z"},"trusted":true},"outputs":[],"source":["data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_user.json\")\n","data = []\n","for line in data_file:\n","  data.append(json.loads(line))\n","user_df = pd.DataFrame(data)\n","data_file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T22:49:02.814483Z","iopub.status.busy":"2023-10-30T22:49:02.814038Z","iopub.status.idle":"2023-10-30T22:49:02.821722Z","shell.execute_reply":"2023-10-30T22:49:02.820347Z","shell.execute_reply.started":"2023-10-30T22:49:02.814451Z"},"trusted":true},"outputs":[],"source":["#Check if all the dataset has already been imported as DataFrames\n","print(type(business_df))\n","print(type(user_df))\n","print(type(checkin_df_exploded))\n","print(type(review_df))\n","print(type(tip_df))"]},{"cell_type":"markdown","metadata":{},"source":["Set the authorization settings for Azure, called engine."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T14:53:56.348809Z","iopub.status.busy":"2023-10-24T14:53:56.348349Z","iopub.status.idle":"2023-10-24T14:54:26.090298Z","shell.execute_reply":"2023-10-24T14:54:26.089032Z","shell.execute_reply.started":"2023-10-24T14:53:56.348772Z"},"trusted":true},"outputs":[],"source":["business_df.to_sql('business', engine, if_exists='replace', index=True, \n","                   dtype={'attributes': sqlalchemy.types.JSON, 'hours': sqlalchemy.types.JSON}, chunksize = 50000)"]},{"cell_type":"markdown","metadata":{},"source":["When importing checkin table to Azure, an error occurs says that the column of date is too long. Considering that the 'date' column is a huge amount of dates, in order to import successfully, Cut off the date and set a upper limit of 255 characters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T15:00:27.035226Z","iopub.status.busy":"2023-10-24T15:00:27.034765Z","iopub.status.idle":"2023-10-24T15:00:29.277384Z","shell.execute_reply":"2023-10-24T15:00:29.276106Z","shell.execute_reply.started":"2023-10-24T15:00:27.035193Z"},"trusted":true},"outputs":[],"source":["max_length = 255 #Set the maximum length for every element in 'date' column\n","checkin_df['date'] = checkin_df['date'].apply(lambda x: x[:max_length] if isinstance(x, str) else x) #Cut off all the characters that is over 255 limit\n","user_df['friends'] = user_df['friends'].apply(lambda x: x[:max_length] if isinstance(x, str) else x) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T22:49:06.992776Z","iopub.status.busy":"2023-10-30T22:49:06.992406Z"},"trusted":true},"outputs":[],"source":["checkin_df_exploded.to_sql('checkin', engine, if_exists='replace', index = True, chunksize = 50000)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T01:13:50.733593Z","iopub.status.busy":"2023-10-24T01:13:50.733149Z","iopub.status.idle":"2023-10-24T01:13:55.264158Z","shell.execute_reply":"2023-10-24T01:13:55.263309Z","shell.execute_reply.started":"2023-10-24T01:13:50.733561Z"},"trusted":true},"outputs":[],"source":["review_df.iloc[:1000].to_sql('review', engine, if_exists='replace', index=True, chunksize = 50000)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T14:57:56.129723Z","iopub.status.busy":"2023-10-24T14:57:56.129343Z","iopub.status.idle":"2023-10-24T14:58:47.413542Z","shell.execute_reply":"2023-10-24T14:58:47.412475Z","shell.execute_reply.started":"2023-10-24T14:57:56.129691Z"},"trusted":true},"outputs":[],"source":["tip_df.to_sql('tip', engine, if_exists='replace', index=True, chunksize = 50000)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T15:00:32.148305Z","iopub.status.busy":"2023-10-24T15:00:32.147911Z","iopub.status.idle":"2023-10-24T15:04:38.088019Z","shell.execute_reply":"2023-10-24T15:04:38.086879Z","shell.execute_reply.started":"2023-10-24T15:00:32.148275Z"},"trusted":true},"outputs":[],"source":["user_df.to_sql('user', engine, if_exists='replace', index=True, chunksize = 50000)"]},{"cell_type":"markdown","metadata":{},"source":["After importing all the tables to Azure, we need to learn the attributes of these tables: **business, checkin, review, tip & user**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T17:36:47.109193Z","iopub.status.busy":"2023-10-24T17:36:47.108372Z","iopub.status.idle":"2023-10-24T17:36:50.349122Z","shell.execute_reply":"2023-10-24T17:36:50.347938Z","shell.execute_reply.started":"2023-10-24T17:36:47.109156Z"},"trusted":true},"outputs":[],"source":["#The query is used to learn the column names and other related information for the five tables\n","query = \"DESCRIBE business;\"\n","description_df = pd.read_sql_query(text(query), engine)\n","print(description_df)"]},{"cell_type":"markdown","metadata":{},"source":["Following code is used for querying the corresponding data from SQL entities: **business, checkin, tip, user & review.**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-30T17:10:59.126532Z","iopub.status.idle":"2023-10-30T17:10:59.126948Z","shell.execute_reply":"2023-10-30T17:10:59.126771Z","shell.execute_reply.started":"2023-10-30T17:10:59.126752Z"},"trusted":true},"outputs":[],"source":["# Define your SQL query as a string\n","query1 = \"SELECT * FROM a12.business where state = 'IL';\"\n","\n","# Use the engine to execute the query and load the result into a DataFrame\n","result_df1 = pd.read_sql_query(text(query), engine)\n","\n","# Now result_df contains the first five rows of your_table_name\n","result_df1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-30T17:10:59.135467Z","iopub.status.idle":"2023-10-30T17:10:59.135903Z","shell.execute_reply":"2023-10-30T17:10:59.135735Z","shell.execute_reply.started":"2023-10-30T17:10:59.135718Z"},"trusted":true},"outputs":[],"source":["# Define your SQL query as a string\n","query2 = \"SELECT * FROM a12.business where stars > 4;\"\n","\n","# Use the engine to execute the query and load the result into a DataFrame\n","result_df2 = pd.read_sql_query(text(query), engine)\n","\n","# Now result_df contains the first five rows of your_table_name\n","result_df2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define your SQL query as a string\n","query3 = \"SELECT * FROM a12.business where stars =5 AND state='IL';\"\n","\n","# Use the engine to execute the query and load the result into a DataFrame\n","result_df3 = pd.read_sql_query(text(query), engine)\n","\n","# Now result_df contains the first five rows of your_table_name\n","result_df3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define your SQL query as a string\n","query4 = \"SELECT name, categories, review_count FROM a12.business WHERE city like 'New Orleans'ORDER BY review_count DESC LIMIT 10;\"\n","\n","# Use the engine to execute the query and load the result into a DataFrame\n","result_df4 = pd.read_sql_query(text(query), engine)\n","\n","# Now result_df contains the first five rows of your_table_name\n","result_df4"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define your SQL query as a string\n","query5 = \"SELECT DISTINCT categories FROM a12.business where stars =5 AND state='IL';\"\n","\n","# Use the engine to execute the query and load the result into a DataFrame\n","result_df5 = pd.read_sql_query(text(query), engine)\n","\n","# Now result_df contains the first five rows of your_table_name\n","result_df5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define your SQL query as a string\n","query6 = \"SELECT name, stars FROM a12.business WHERE city = 'New Orleans' AND review_count > 100 ORDER BY stars DESC LIMIT 5;;\"\n","\n","# Use the engine to execute the query and load the result into a DataFrame\n","result_df6 = pd.read_sql_query(text(query), engine)\n","\n","# Now result_df contains the first five rows of your_table_name\n","result_df6"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define your SQL query as a string\n","query7 = \"SELECT categories, COUNT(*) AS count FROM a.12business WHERE city = 'New Orleans' AND stars > 4.5 GROUP BY categories ORDER BY count DESC LIMIT 5;\"\n","\n","# Use the engine to execute the query and load the result into a DataFrame\n","result_df7 = pd.read_sql_query(text(query), engine)\n","\n","# Now result_df contains the first five rows of your_table_name\n","result_df7"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define your SQL query as a string\n","query8 = \"SELECT categories, AVG(review_count) AS avg_review_count FROM a12.business WHERE city = 'New Orleans' GROUP BY categories ORDER BY avg_review_count DESC;\"\n","\n","# Use the engine to execute the query and load the result into a DataFrame\n","result_df8 = pd.read_sql_query(text(query), engine)\n","\n","# Now result_df contains the first five rows of your_table_name\n","result_df8"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define your SQL query as a string\n","query9 = \"SELECT b.name, AVG(r.stars) AS avg_stars, COUNT(r.review_id) AS number_of_reviews FROM a12.business b JOIN review r ON b.business_id = r.business_id WHERE b.city = 'New Orleans'GROUP BY b.name;\"\n","\n","# Use the engine to execute the query and load the result into a DataFrame\n","result_df9 = pd.read_sql_query(text(query), engine)\n","\n","# Now result_df contains the first five rows of your_table_name\n","result_df9"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define your SQL query as a string\n","query10 = \"SELECT b.categories AS category, COUNT(chk.business_id) AS total_checkins FROM a12.business b JOIN checkin chk ON b.business_id = chk.business_id WHERE b.city = 'New Orleans' GROUP BY b.categories ORDER BY total_checkins DESC LIMIT 5;\"\n","\n","# Use the engine to execute the query and load the result into a DataFrame\n","result_df10 = pd.read_sql_query(text(query), engine)\n","\n","# Now result_df contains the first five rows of your_table_name\n","result_df10"]},{"cell_type":"markdown","metadata":{},"source":["**In case anyone need to delete a table, please use the following code, otherwise, don't change the code and run it:**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T00:20:17.807459Z","iopub.status.busy":"2023-10-24T00:20:17.806998Z","iopub.status.idle":"2023-10-24T00:20:17.813479Z","shell.execute_reply":"2023-10-24T00:20:17.812040Z","shell.execute_reply.started":"2023-10-24T00:20:17.807414Z"},"trusted":true},"outputs":[],"source":["from sqlalchemy import inspect\n","from sqlalchemy import MetaData, Table\n","\n","def table_exists(name, con):\n","    inspector = inspect(con)\n","    return name in inspector.get_table_names()\n","\n","metadata = MetaData()\n","\n","# Drop the table if it exists. Please replace the 'table_name' to the target table name\n","if table_exists('table_name', engine):\n","    table = Table('table_name', metadata)\n","    table.drop(engine)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
